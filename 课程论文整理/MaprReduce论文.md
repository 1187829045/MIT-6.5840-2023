## 概念：
MapReduce 是一种编程模型，用于处理和生成超大规模的数据集。用户首先定义一个 Map 函数，处理基于 key/value 对的数据集合，输出一个中间的 key/value
对数据集合。随后，用户再定义一个 Reduce 函数，用于合并所有具有相同中间 key 值的中间 value 值。

## 运行概括：
举个例子，有一个文档集合，统计文档中单词出现的数量 ，首先我们有M个Map 工作节点去做map操作，有R个reduce节点去做Reduce操作。首先将这个文档集合分成M份，
分别把每一份发往一个Map工作节点去做map操作，将分到的集合进行统计每个单词出现的次数（这就是根据输入生成的中间结果），Map函数生成并输出中间的key/value对，并将其缓存在内存中。
缓存中的key/value对通过分区函数分成R个区域，并周期性地写入本地磁盘。存储位置会被回传给master，由master负责将这些信息传送给Reduce worker。
当Reduce worker程序接收到master发来的数据存储位置信息后，使用RPC从Map worker所在主机的磁盘上读取这些缓存数据。Reduce worker读取完所有中间数据后，
对key进行排序，使得相同key值的数据聚合在一起。如果中间数据太大，无法在内存中完成排序，则需要进行外部排序。Reduce worker程序遍历排序后的中间数据，
对于每一个唯一的中间key值，将其与相关的中间value值集合传递给用户自定义的Reduce函数。Reduce函数的输出被追加到对应分区的输出文件中。当所有的Map和Reduce任务完成后，
master会唤醒用户程序。在此时，MapReduce调用将返回，标志着整个处理流程的结束。



## Master数据结构
Master节点持有一些关键的数据结构，主要用于存储每个Map和Reduce任务的状态（如空闲、工作中或完成），以及正在处理任务的Worker节点的标识。
Master的角色类似于一个数据管道，负责将中间文件的存储位置信息从Map任务传递到Reduce任务。因此，对于每个已完成的Map任务，
Master会存储生成的R个中间文件的大小和位置。当Map任务完成时，Master会接收到位置和大小的更新信息，并将这些信息推送给正在进行Reduce任务的Worker。


## 容错
MapReduce库的设计目标是处理超大规模数据集，因此需要有效的容错机制。

### Worker故障
Master会定期向每个Worker发送ping请求。如果在约定的时间范围内没有收到Worker的响应，Master会将该Worker标记为失效。
所有由失效Worker完成的Map任务将重置为初始的空闲状态，并重新安排给其他Worker。
此外，失效Worker正在运行的Map或Reduce任务也会被重新标记为空闲状态，等待重新调度。

当Worker故障时，Map任务的输出存储在该Worker上，因而必须重新执行，而已完成的Reduce任务的输出存储在全局文件系统上，因此无需重新执行。
如果一个Map任务在WorkerA上执行后因故障转移到Worker B，那么这个“重新执行”的动作会通知所有执行Reduce任务的Worker。
任何尚未从Worker A读取数据的Reduce任务将会从Worker B读取数据。MapReduce能够处理大规模Worker失效的情况，例如在进行网络维护期间，
80台机器在几分钟内不可访问，Master只需简单地重新执行这些Worker完成的工作，之后继续未完成的任务，直到最终完成MapReduce操作。


### Master故障
为了解决Master故障的问题，一个简单的办法是让Master周期性地将其数据结构（如3.2节中描述的）写入磁盘，即进行检查点（checkpoint）。
如果Master失效，可以从最后一个检查点重新启动另一个Master进程。然而，由于仅有一个Master进程，恢复过程比较麻烦，因此在当前实现中，
如果Master失效，将中止MapReduce运算。用户可以检查到这种状态，并根据需要重新执行MapReduce操作。

### 失效处理机制

当用户提供的Map和Reduce操作是确定性函数时（即相同输入产生相同输出），我们的分布式实现的输出与所有操作顺序执行时的输出是一致的。
我们依赖于对Map和Reduce任务输出的原子提交来实现这一特性。每个正在运行的任务会将其输出写入私有的临时文件中。
每个Reduce任务生成一个临时文件，而每个Map任务则生成R个这样的文件。当Map任务完成时，Worker会向Master发送包含R个临时文件名的完成消息。
如果Master再次从已完成的Map任务接收到完成消息，它将忽略该消息；否则，Master会将这R个文件名记录在数据结构中。

当Reduce任务完成时，Reduce Worker进程会以原子的方式将临时文件重命名为最终输出文件。如果同一Reduce任务在多台机器上执行，
将会有多个重命名操作进行。我们依赖底层文件系统提供的原子重命名操作，以确保最终的文件系统状态仅包含一个Reduce任务产生的数据。

## 存储位置
在计算运行环境中，网络带宽是一个稀缺资源。因此，为了节省带宽，我们尽量将输入数据（由 GFS 管理）存储在集群中机器的本地磁盘上。
GFS 将每个文件按 64MB 的块（Block）进行分隔，并将每个块保存在多台机器上，通常保留三份拷贝。
在调度Map任务时，MapReduce的master会考虑输入文件的位置信息，尽量将 Map 任务调度在包含相关输入数据拷贝的机器上执行。
如果无法实现，master会尝试将任务分配到与包含输入数据的机器在同一交换机（switch）上的其他机器。通过这种方式，在大型集群上运行 MapReduce 操作时，大部分输入数据能够从本地读取，从而减少了网络带宽的消耗。

## 任务粒度
我们将 Map 任务拆分为 M 个片段，将 Reduce 任务拆分为 R 个片段进行执行。在理想情况下，M 和 R 应该远多于集群中的 worker 数量。
这样可以提高集群的动态负载均衡能力，并加快故障恢复速度：失效机器上执行的多个 Map 任务可以迅速分配到其他可用的 worker 上执行。
然而，在具体实现中，M 和 R 的取值受到一定限制，因为 master 必须执行 O(M+R) 次调度，并在内存中保存 O(MR) 个状态。
虽然 O(MR) 对内存的影响相对较小（大约每对 Map 和 Reduce 任务只需要 1 字节），但仍需考虑。
此外，R 的值通常由用户指定，因为每个 Reduce 任务最终生成一个独立的输出文件。实际使用中，我们倾向于选择合适的 M 值，
使每个独立任务处理大约 16MB 到 64MB 的输入数据，以便优化输入数据的本地存储策略。
同时，我们将 R 设置为所使用的 worker 机器数量的小倍数。通常，我们会采用 M=200,000 和 R=5,000 的比例，使用 2,000 台 worker 机器来执行 MapReduce 操作。


## 备用任务
影响一个 MapReduce 操作总执行时间的最常见因素是“落伍者”。在运算过程中，如果某台机器花费较长时间才完成最后几个 Map 或 Reduce 任务，
会导致 MapReduce 操作的总执行时间超过预期。出现“落伍者”的原因有很多。例如，某台机器的硬盘出现问题，读取时需要频繁进行错误纠正，导致读取速度从 30MB/s 降低到 1MB/s。
此外，如果集群的调度系统在这台机器上又调度了其他任务，由于 CPU、内存、本地硬盘和网络带宽等资源的竞争，执行 MapReduce 代码的效率会更加低下。
为了解决“落伍者”问题，采用了一个通用的机制。当一个 MapReduce 操作接近完成时，master 会调度备用（backup）任务来执行剩下的处于处理中状态的任务。
无论是最初的执行进程还是备用任务完成了任务，我们都会将该任务标记为已完成。我们对这个机制进行了优化，通常只会占用比正常操作多几个百分点的计算资源。
通过这种机制，我们发现能够显著减少超大 MapReduce 操作的总处理时间。


## 技巧
虽然简单的 Map 和 Reduce 函数已经能够满足大部分计算需求，还是有一些有价值的扩展功能。

### 分区函数
使用 MapReduce 时，用户通常会指定 Reduce 任务及其输出文件的数量 (R)。我们利用分区函数对中间数据进行分区，然后将这些数据输入到后续任务中。
默认的分区函数使用 hash 方法 (例如，hash(key) mod R) 来进行分区，这样可以产生均衡的分区。然而，在某些情况下，其他分区函数可能会更有用。
例如，若输出的 key 值为 URLs，可能希望每个主机的所有条目保存在同一个输出文件中。为此，用户需要提供专门的分区函数，比如使用 hash(Hostname(urlkey)) mod R。

### 顺序保证
我们确保在给定分区中，中间 key/value 对的数据处理顺序是按 key 值的增量顺序进行的。这种顺序保证生成有序的输出文件，对需要随机存取输出文件的应用非常重要， 同时也有助于对排序输出的数据集进行处理。

### Combiner 函数
在某些情况下，Map 函数产生的重复中间 key 值数据占很大比重，并且用户自定义的 Reduce 函数满足结合律和交换律。比如，在词频统计程序中，
每个 Map 任务会生成大量记录 <the, 1>。为了优化性能，我们允许用户指定一个可选的 Combiner 函数，该函数在本地合并这些记录后再发送到 Reduce 任务。
Combiner 函数通常和 Reduce 函数相同，区别在于它的输出写入中间文件，而 Reduce 函数的输出则保存在最终输出文件中。

### 输入和输出的类型
MapReduce 库支持多种输入数据格式。例如，文本模式的输入数据每一行视为一个 key/value 对，key 是文件的偏移量，value 是该行内容。
用户可以通过实现一个简单的 Reader 接口来支持新的输入类型。Reader 不一定要从文件中读取数据，可以实现从数据库读取记录的 Reader。
同时，用户也可以定义新的输出类型，以便生成不同格式的数据。

### 副作用
在某些情况下，用户希望在 Map 或 Reduce 操作过程中生成辅助输出文件。我们通过程序写入器将这些“副作用”变成原子和幂等的操作。
程序会先将输出结果写入临时文件，待所有数据处理完成后，使用系统级的原子操作重命名该文件。如果任务产生多个输出文件，则需要注意一致性要求，这种情况下必须确保任务是确定性的。

### 跳过损坏的记录
有时，用户程序中的 bug 导致 Map 或 Reduce 函数在处理某些记录时崩溃，进而导致 MapReduce 操作无法完成。常见的解决方法是修复 bug 后重新执行操作，
但找出 bug 并修复可能并不容易。我们提供了一种模式，允许 MapReduce 跳过导致崩溃的记录，从而保证处理能继续进行。
每个 worker 进程设置了信号处理函数来捕获内存段异常和总线错误。在执行 Map 或 Reduce 操作之前，MapReduce 库会保存记录序号。
若用户程序触发系统信号，消息处理函数会向 master 发送最后处理的记录序号。如果某条特定记录导致失败多次，master 会标记该记录并在下次重新执行任务时跳过它。


### 本地执行
调试 Map 和 Reduce 函数的错误通常非常困难，因为这些操作分布在多个计算机上执行，且具体的执行位置由 Master 动态调度。这增加了调试的复杂性。
为了解决这个问题，我们开发了一套本地实现版本的 MapReduce 库，允许用户在本地计算机上顺序执行 MapReduce 操作。用户可以通过设定特殊标志来在本地执行他们的程序，
从而利用本地调试和测试工具（如 gdb）进行调试。

### 状态信息
Master 使用嵌入式 HTTP 服务器（例如 Jetty）来显示一组状态信息页面，用户可以通过这些页面监控各种执行状态。状态页面显示了计算的进度，包括已完成的任务数量、
正在处理的任务数量、输入字节数、中间数据字节数、输出字节数和处理百分比等。此外，页面还包含指向每个任务的 stderr 和 stdout 文件的链接。
用户可以根据这些数据预测计算的总时间，并决定是否需要增加额外的计算资源。这些页面也有助于分析计算执行比预期慢的原因。
在状态页面的顶层，用户可以看到哪些 worker 机器失效，以及它们失效时正在运行的 Map 和 Reduce 任务。这些信息对于调试用户代码中的错误非常有帮助。
