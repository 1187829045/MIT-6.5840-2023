# Lab2

首先该算法核心成员是:领导者，跟随着以及候选者三种身份，日志条目仅从领导者流向其他服务器。Raft 使用随机定时器来选举领导者。还有一个很关键的概念，
复制状态机：复制状态机被用于解决分布式系统中的多种容错问题。例如，许多依赖单一集群领导者的大型系统，通常使用一个独立的复制状态机来管理领导者选举，
并存储必须在领导者崩溃后仍然可用的配置信息。复制状态机通常通过一个复制日志来实现。每个服务器都存储一个包含一系列命令的日志，其状态机会按顺序执行这些
命令。每份日志都包含相同的命令且顺序一致，因此每台状态机会处理相同的命令序列。由于状态机是确定性的，它们会计算出相同的状态和相同的输出序列。保持复制
日志的一致性是共识算法的工作。服务器上的共识模块接收来自客户端的命令，并将其添加到日志中。它通过与其他服务器上的共识模块通信，确保每份日志最终都包含
相同的请求并以相同的顺序排列，即使某些服务器发生故障也是如此。当命令被正确复制后，每台服务器的状态机会按日志顺序处理这些命令， 并将输出返回给客户端。
最终，这些服务器对外表现为一个高度可靠的单一状态机。Raft是一种用于管理复制日志的算法，Raft 通过首先选举出一个领导者来实现共识，然后赋予领导者完全
的责任来管理复制日志。领导者负责从客户端接收日志条目,将它们复制到其他服务器，并告知这些服务器何时可以将日志条目安全地应用到它们的状态机中。leader
和follower之间通信主要有两个方法一个是AppendEntries另一个是RequestVote, AppendEntries有两个作用一个是同步日志另一个是发送心跳，发送心跳的
时候，其中要同步的日志条目就为空,会先判断当前的任期是不是大于或等于接收者的任期，如果小于那么接收者会返回false。Leader 通过 AppendEntries 消息
定期发送心跳信号，确保 Follower 知道当前 Leader，并防止 Follower 触发选举。当有新的日志条目产生时，Leader 会将其复制到 Follower。Leader 
等待大多数 Follower 的确认后，将日志条目标记为已提交 （通过更新 commitIndex）。Follower 接收到更新的commitIndex后，将日志条目应用到状态机，
保持状态一致性。 

当领导者选举完成，它开始处理客户端请求。每个客户端请求包含一个命令，供复制的状态机执行。领导者将命令作为新条目追加到自己的日志中，然后并行向集群中
的其他服务器发送 AppendEntries RPC来复制该条目。当条目被安全地复制后，领导者将该条目应用到自己的状态机，并将执行结果返回给客户端。如果跟随者崩溃
或运行缓慢，或者网络数据包丢失，领导者会无限期地重试 AppendEntries RPC（即使它已经向客户端返回了响应），直到所有的跟随者最终存储所有日志条目。日
志条目中的任期号用于检测日志之间的不一致性.每个日志条目还具有一个整数索引，用来标识它在日志中的位置。领导者决定何时可以安全地将日志条目应用到状态机，
这样的条目称为已提交条目。**Raft 保证已提交的条目是持久的，并最终会被所有可用的状态机执行。**一旦创建该条目的领导者将其复制到大多数服务器上，该条
目就会被提交.这也会提交领导者日志中的所有前置条目，包括由前一个领导者创建的条目。

领导者会跟踪它知道的最高已提交条目的索引，并将该索引包含在未来的 AppendEntries RPC 中（包括心跳），以便其他服务器最终得知。一旦跟随者得知某个日
志条目已提交，它会按日志顺序将该条目应用到本地状态机。如果不同日志中的两个条目具有相同的索引和任期，则它们存储相同的命令。如果不同日志中的两个条目具
有相同的索引和任期，则它们在所有前置条目中的内容完全相同。在正常操作中，领导者和跟随者的日志保持一致，因此 AppendEntries 一致性检查不会失败。然而
领导者崩溃可能导致日志不一致（旧领导者可能没有完全复制日志中的所有条目）。这些不一致性可能会在一系列领导者和跟随者崩溃后加剧.在 Raft中，领导者通过
强制跟随者的日志与其自己的日志一致来处理不一致性。这意味着，跟随者日志中的冲突条目将被领导者日志中的条目覆盖。为了使跟随者的日志与自己的日志一致，领
导者必须找到两个日志中最新的相同条目，然后删除跟随者日志中该条目之后的所有条目，并将领导者在此之后的所有条目发送给跟随者。所有这些操作都在 AppendE
ntries RPC 执行一致性检查时发生。领导者为每个跟随者维护一个 nextIndex，该值表示领导者将发送给该跟随者的下一个日志条目的索引。当领导者首次上任时
，它会将所有的 nextIndex 值初始化为它日志中最后一个条目之后的索引。如果跟随者的日志与领导者的日志不一致，AppendEntries 一致性检查将在下一次 A
ppendEntries RPC 中失败。在拒绝后，领导者会将 nextIndex 值减小，并重试 AppendEntries RPC。最终，nextIndex 会到达一个点，在该点领导者和
跟随者的日志将匹配。当发生这种情况时，AppendEntries 将成功执行，从而删除跟随者日志中的任何冲突条目，并附加领导者日志中的条目（如果有）。一旦 App
endEntries 成功，跟随者的日志将与领导者的日志一致，并且在该任期内将保持一致。如果需要，可以优化协议以减少拒绝的 AppendEntries RPC 数量。例如，
当拒绝一个 AppendEntries 请求时，跟随者可以包含冲突条目的任期和该任期的第一个条目的索引。有了这些信息，领导者可以减少 nextIndex，以跳过该任期中
的所有冲突条目；这样，每个有冲突条目的任期只需要一次 AppendEntries RPC，而不是每个条目都需要一次 RPC。通过这个机制，领导者在上任时不需要采取任何
特别的措施来恢复日志一致性。它只需要开始正常操作，日志会自动在 AppendEntries 一致性检查的响应中趋于一致。领导者永远不会覆盖或删除自己日志中的条目：
只要大多数服务器处于正常状态，Raft 就可以接受、复制和应用新的日志条目；在正常情况下，一个新的条目可以通过一次对集群大多数服务器的 RPC 来完成复制；
一个慢速跟随者不会影响性能。
## Part A

踩坑 ： 
1. 当选举人的任期必须要大于被选举的任期，不能等于，等于会造成 双leader情况
2. 当两个都是候选者，低任期应该为高任期投票
3. 应该避免锁住多个函数调用,这样会造成延迟,当A 节点发送给B节点心跳,由于这个原因导致B节点接收到心跳就超时了
4. 死锁的发生 由于一个函数调用多个函数且都使用了 defer unlock 函数调用导致了死锁,当用 携程 启动另一个有锁的函数时,不会死锁
实现 Raft 的领导者选举和心跳功能（AppendEntries RPC 不携带日志条目）。2A 部分的目标是确保系统能够选出一个领导者，
在没有故障的情况下领导者能够持续担任其角色，并且当旧的领导者失效或通信丢失时，新领导者能够接任       


理清代码逻辑：首先就是在创建好一个节点后，该节点的状态应该为候选者，然后选举间隔，如果在选举间隔时间超时前收到领导者心跳那么就变为跟随着，如果超时没收到，
那么发起选举，这时候又有多种情况，如果得到半数的选票，那么成为领导者，并立刻发送心跳给跟随者，收到心跳的跟随者应该也重置选举间隔和心跳检测
(要不要重置选举定时器)。如果没有收到半数的选票，并且收到比自己节点大的任期应该更新自己的任期为更大任期，并转为跟随者（这里可能错误了）。
应该是在心跳超时的时候从跟随者转变为候选者。


## Part B
1. 区分 是心跳还是日志复制分别处理
2. 领导者选举时候不能单一考虑任期大小，应该加入考虑拥有的日志，比如不能让一个没有任何日志但是任期
特别大的成为领导者，以为可能是他断开连接后，不断的发起选举

例子（1）如果发起选举的是C节点，则因为日志不是最新的，不可能成为leader, 
但是此次rpc广播会让节点A，B更新任期为6（ 节点C发起投票前会自增任期）, 
所以此时集群中所有的节点的任期都是6，所以下一次选举时间先 到期的可能是A或者B，
因为再依据日志的新旧程度选择A或者B，两者都有可能成为新的leader （2）如果是B节点先超时，
则因为任期自增后是2都比其他节点小，也不可能成为leader，但是根据其他节点的响应会更新任期 到5，
重置自己的选举周期，所以下一次选举率先超时的可能是A或者C，如果C先到达超时时间，则会自增任期到6，
然后 重置自己的选举周期，发送rpc广播，其他节点收到后会更新任期但是拒绝投票，因为C的日志不是最新的
，所以最终A的 选举周期超时，开始term=7的选举，随后因为日志记录最新且任期不小于其他节点，
所以成功当选leader （3）如果是A节点先超时，则它在任期等于6的时候发起投票，并且会成为leader，
因为它是前leader 的日志是最新的并且任期大于其他节点
3. 下面是一个从节点的判断流程：
首先会判断PrevLogIndex是否越界(PrevLogIndex<FirstLogIndex || PrevLogIndex>rf.LastLogIndex)， 
如果越界则返回false,从节点同时返回主结点自己的rf.LastLogIndex以及rf.LastLogTerm，主结点随后会 
在随后的AppendEntries RPC请求中会将从节点返回的LastLogIndex位置上的及其后面的日志发送给该从节点
如果PrevLogIndex没有越界(PrevLogIndex>=FirstLogIndex && PrevLogIndex<=rf.LastLogIndex)， 
则从节点会先判断在该索引上的日志的任期是否等于args.PrevLogTerm， 如果等于则会可以执行日志覆盖或者添加操作。
具体的流程是会逐项遍历主结点发过来的日志, 对于处于PrevLogIndex到LastLogIndex的日志项， 对于每一项，
如果发现有主结点的对应日志的任期号和自己该索引上日志的任期号不一致，则覆盖该项日志，否则比较下一项
对于大于LastLogIndex的日志项，会执行append操作将日志项添加到自身的日志末尾。从节点随后会更新自己的commitIndex
如果从节点在索引PrevLogIndex上的日志的任期不等于args.PrevLogTerm，如果采用nextIndex递减算法，则响应参数 
跟(PrevLogIndex<FirstLogIndex || PrevLogIndex>rf.LastLogIndex)的情况是一样的（
HandleAppendEntriesRPC2 和HandleAppendEntriesRPC2 搭配使用实现）； 如果采用优化的nextIndex跳跃算法
可以参考（HandleAppendEntriesRPC 和HandleAppendEntriesRPC的搭配）
从一个leader节点来看：
首先会设置请求体，包括自己的任期号，commitIndex，PrevLogIndex, PrevLogTerm以及PrevLogIndex后的日志项，
给从节点后，如果从节点成功复制了日志，则返回true给主节点，这个时候主节点可以更新自己的数据结构中关于该从节点的 
matchIndex和commitIndex，随后会尝试一次将matchIndex传入状态机中，更新lastApplied字段。
如果leader收到了失败信息，则看看是不是自己的任期过小，则更新任期，角色转换为follower，再等待集群中选举出新leader

